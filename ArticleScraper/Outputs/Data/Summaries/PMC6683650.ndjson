{"summary": "word embedding trained by electronic health records (EHRs) is considered the best. but the vocabulary diversity is limited by previous medical records. we need a word embedding model that maintains the vocabulary diversity of open internet databases. projection PubMed and Wikipedia embeddings had highest testing mean F-measure (0.7362 and 0.6693 in Tri-Service General Hospital and the seven other hospitals, respectively) hybrid sampling method was found to improve the model performance. more than 300 contributions have successfully applied deep-learning technology in medical image analysis [20]. the most popular word embedding models, such as word2vec [26], currently need large free-text resources. most popular word embedding models, such as word2vec [26], currently need large free-text resources. word embedding combined with a convolutional neural network (CNN) exhibited outstanding performance compared with traditional methods [29] but its performance is still deficient compared with human experts. rule-based approaches for conducting disease coding have demonstrated superior performance. the three corpora were used to train the traditional word2vec model. a recent word embedding comparison study showed that word embedding trained using EHRs can usually better capture medical semantics. this difference was present in previous studies, despite a larger data volume in their EHRs. the traditional word2vec model was trained by larger internet corpora (ie, Wikipedia and PubMed) and (2) the embedding layer was fixed and a projection word2vec model was trained by the smaller internal corpus (ie, EHRs) the detailed projection word2vec model architecture started from an embedding layer followed by a fully connected layer for linear projection. a relation score of 391 for the terms \u201ccataracts\u201d and \u201cinsulin\u201d and a score of 1142 for the terms \u201cobesity\u201d and \u201cdiabetes\u201d indicated that the similarity of the second pair was higher. the relation scores of each word embedding model were defined as the cosine similarity. we collected 119,315 discharge notes from the hospital and corrected misspellings using the R hunspell version 2.3 package developed by Jeroen Ooms. all ICD-10-CM codes were truncated at the three-character level. this study included data from seven hospitals. certain infectious and parasitic diseases 14,883 (18.1) 2296 (18.9) 4713 (19) 14,704 (19.8) C00-D49 Neoplasms 29,125 (35.4) 4405 (36.3) 8721 (35.2) 7220 (9.7) D50-D89 Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism 8707 (10.6) 1062 (8.7) 2258 (9.1) 7112 (9.6) E00-E89 Endocrine, nutritional, N00-N99 Diseases of the genitourinary system 19,454 (23.6) 2782 (22.9) 5934 (23.9) 18,345 (24.7) O00-O9A Pregnancy, childbirth, and the puerperium 2195 (2.7) 311 (2.6) 632 (2.6) 1409 (1.9) P00-P96 Certain conditions originating in the perinatal period 840 (1) 106 (0.9) 179 (0.7) 375 (0.5) Q00 artificial intelligence model one study proposed a model combining a word embedding model and a CNN. the input data is an n1 word sequence, which is converted to a 50n1 matrix through a designated embedding table. this matrix is analyzed by our analysis unit, and the output is a vector. the number of outputs of the first logistic output layer was revised to the number of the three-character-level ICD-10-CM codes in different one\u2013character-level ICD-10-CM codes. each output probabilities pass the maximum pooling-layer grouping by their specific two\u2013character-level ICD-10-CM codes, followed by a maximum pooling layer for the one\u2013character-level ICD-10-CM code identification. situations e and f are similar to situations b and c, but the cross-entropy was used as the loss function in this study. we weighed the benefits of cross-entropy on the basis of the frequency of each code. hybrid sampling is a key method for avoiding overfitting. word2vec [26] is the most popular word embedding model. we used two internet corpora\u2014English Wikipedia and PubMed journal abstracts\u2014and an internal task corpus\u2014the EHRs of discharge notes. the total number of words in our EHRs was approximately 30,000. using this method, we revised the traditional word2vec model. the traditional word2vec model has two trainable layers. the embedding weights can be used to express the terminology meanings. the method of combination is a simple concatenation of two vectors. the length of the vector will be changed to 100. we will only compare the performance of the simple combination and our projection word2vec model in medical semantic understanding. the top five most similar words were shown to provide qualitative evidence for measuring the performance of each word2vec model. we collected 119,315 discharge notes from the hospital and corrected misspellings using the R hunspell version 2.3 package developed by Jeroen Ooms. ICD-10-CMa code Definition Dataset Training setb (n=82,390), n (%) Validation setc (n=12,145), n (%) Testing set 1d (n=24,780), n (%) Testing set 2e (n=74,332), n (%) A00-B99 Certain infectious and parasitic diseases 14,883 (18.1) 2296 (18.9) 4713 (19) 14,704 (19.8) C00-D49 Neoplasms 29, K00-K95 Diseases of the digestive system 20,621 (25) 2969 (24.4) 5956 24) 22,500 (30.3) L00-L99 Diseases of the skin and subcutaneous tissue 4217 (5.1) 702 (5.8) 1347 (5.4) 5297 (7.1) M00-M99 Diseases of the musculoskeletal system and connective tissue 12,030 (14.6) 1697 (14) 3525 (14.2) 10,801 (14.5) N00-N99 Diseases of artificial intelligence model one study proposed a model combining a word embedding model and a CNN. the input data is an n1 word sequence, which is converted to a 50n1 matrix through a designated embedding table. this matrix is analyzed by our analysis unit, and the output is a vector. in the double-channel model, we designed K1, K2, K3, K4, and K5 to be 2400, 1800, 900, 600, and 300, respectively, in the one-channel model. a revision of the previous model is the ICD classification unit. situation g is also an integrated model combining situations e and f. we used the R MXNet version 1.3.0 package developed by Distributed (Deep) machine learning community to implement the aforementioned architecture. if human experts consider a discharge note not involving cancer, they will verify that there are no cancer-related terms. results We tested word embeddings on seven published biomedical measurement datasets commonly used to measure semantic similarity between medical terms. our EHR embeddings also yielded the highest correlation of 0.6082 in MayoSRS. the correlations of PubMed and Wikipedia embeddings increased from 0.5087 to 0.5148 and from 0.0082 to 0.0930 respectively. the original PubMed embeddings yielded the highest correlation of 0.7200 in MiniMayoSRS. the projection word2vec model successfully improved the performance of only Wikipedia embeddings. the simple concatenation embeddings look slightly better than projection embeddings. the results of simple concatenation embeddings resemble those of combining the first five words of two embeddings and reordering them. the results of simple concatenation embeddings resemble those of combining the first five words of two embeddings and reordering them. tensive hyperlipidemia Diabetes Hypertensive Diabetes Hypertensive Pulmonary Renovascular Dyslipidemia Cardiovascular Hypertensive Chronic Dyslipidemia Chronic Mellitus Asthma Normotension HCVD Pulmonary Cardiovascular Disease Hyperlipidemia Chronic Dyslipidemia Hyperuricemia Asthma Hypercholesterolemia Acute Dyslipidemia Diabetes Hypertension Mellitus Hypertension Mellitus Hypertension Mellitus Cancer Diabetic DM Cardiovascular Diabetics we only present the results of the 90% most used three-character-level codes. the performance of the model trained by PubMed embeddings was worse than that of Wikipedia and EHR embeddings. the integrated model that used both Wikipedia and PubMed embeddings (0.7208) achieved similar performance to the model that used only Wikipedia embeddings in the first and second test sets. the details of all precisions, recalls, and F-measures are presented in Multimedia Appendix 2. Table 4. Results of the three-character-level ICD-10-CM coding task using different word embeddings. we compared the predictions of each word in the model with (situation h in Table 4) and without (situation g in Table 4) hybrid sampling training. the prediction values are defined as the last fully connected output before logistic transformation; therefore, a value greater than 0 implies that the model results in a probability greater than 50% for only single\u2013character-level words. ICD-10-CM coding results of selected models in several simulated discharge notes. ICD-10-CM coding results of selected models in several simulated discharge notes. projection Wikipedia embeddings and PubMed embeddings trained by the traditional word2vec model have a similar ability to capture medical semantic properties. the model that used both projection Wikipedia and PubMed embeddings was the best of them. projection word2vec model exhibited the worst performance in multiple tasks compared with that using Wikipedia embeddings. the proposed projection word2vec model can deal with the vocabulary size problem in the medical NLP task but also be used in other fields that require confidentiality of data. the mayoSRS included more symptom and sign words than the other datasets. the embeddings trained by EHRs are superior in capturing symptom or sign semantics. the projection model may only enforce a part of the medical terminology understanding. we propose a double-channel model that includes both Wikipedia and PubMed embeddings to solve this problem. this model improved the vocabulary size because the vocabularies are highly inconsistent in Wikipedia and PubMed but also achieved the best performance in our ICD-10-CM coding experiments. a fully automatic model applied in practical use should be able to handle this challenge. we expect this technique to be widely used in subsequent disease coding research. only positive descriptions will be presented for some free-text document classification tasks. the correlations of our EHR embeddings in the database consisting of seven medical term pairs were not lower than the correlations in these studies. this study used only a set of hyperparameters for all model trainings due to limitations of computing resources. the model performance was better than that of previously proposed methods."}