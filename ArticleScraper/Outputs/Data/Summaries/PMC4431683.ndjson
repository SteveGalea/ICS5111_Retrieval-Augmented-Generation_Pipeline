{"summary": "despite preventive efforts and educational activities for seasonal influenza in the united states, on average 5%\u201320% of the population gets influenza [1], more than 200,000 people [1] are hospitalized from seasonal influenza complications, and 3,000\u201349,000 people die each year [2]. the result is a significant public health and economic burden for the U.S. population [3\u20135]. ILINet data represent the collection of outpatient data from over 3,000 hospitals and doctors\u2019 offices across the u.s. each week, these locations report the total number of patient visits and the number of those visits that were seen for ILI. Wikipedia access logs for articles highly correlated with influenza prevalence improve our knowledge of the current influenza incidence in the u.s. the method for generating probabilistic forecasts with a deterministic mathematical model based on observed data has been well developed. the majority tune a differential equation-based compartmental disease model [26, 28\u201330, 32, 33, 36, 37, 45], but some forecasts have been formed using agent based simulations [27, 31, 41] or spatial models [34, 35] each of these examples rely on defining a prior distribution for the parameterization and initialization of the underlying model. this method can be generalized to any dataset pertaining to disease spread and disease model. five articles from the English language edition of Wikipedia were selected for estimation of present national ILI using the methods described in [15]. the correlation between each of the 50 articles access log time series and the U.S. ILI data was computed. the weekly article request data for each article can be written as independent variables x 1, x 2,..., x 5. this forms our regression vector X = (1, x 1, x 2,..., x 5, ILI 1). model description We only model the U.S. ILI data during the part of the year that we designate as the influenza season. a fixed maximum possible length influenza season would include the earliest possible ramp up of the flu season and the latest possible tapering off. Fig 2. Defining a maximum influenza season. we highlight the weeks corresponding to our maximum influenza season. we can only hope to forecast one pre-defined season at a time. we still believe the presentation of our results using a single strain model to be informative especially since one will always have to weigh the cost of model parameter explosion. an influenza model with no spatial heterogeneity would consist of 2n1(n+2) independent equations [60] compared to the three independent equations we must identify in (2). the transmission rate function is chosen to be a smooth, five times differentiable bump function ranging between 0(1+) at the peak of flu transmission and 0(1) at the low point. the max transmission and minimum transmission levels attained are then controlled by 0 and. prior distribution estimation We start by specifying a distribution of model parameterizations that we will consider before any observations from the 2013\u20132014 season are available. this prior distribution specifies what we think is possible to observe in the new influenza season. this prior distribution is broad enough to assign a high likelihood to any of the past influenza seasons. the link between our epidemiological model and the data is obtained from the infected proportion at the discrete time points. for each season\u2019s data, i = 1, 2,..., M, we can determine an allowable p i by approximately solving the non-linear optimization problem p i = arg min p d 1 : K i - M p [ 1 : K ] 2, (9) where denotes the root sum of squares discrepancy over the discrete we have chosen a log-normal distribution for 0(p) since physically all terms in p must be positive and the relation of the log-normal to a Gaussian distribution makes it a convenient choice. data assimilation An iterative data assimilation process is implemented to continually adjust the parameters and initial state of the seasonal S EIR model. the model can be propagated through the end of flu season to create an informed forecast. the enKS method we use is more sensitive to the underlying dynamics of the data timeseries. if the model state is adjusted directly each time an observation is made, the forecast epidemic curve may not represent any single realization of the model. this makes it difficult to judge systematic model error and thus identify specific areas where the model may be improved. for each week in the simulation, we receive the ILI data and a Wikipedia estimate of the ILI data the following week. d 1:K corresponds to the most current week instead of the last week in the season. the link between our epidemiological model and the data is again obtained from the simulated infected proportion at the time the most recent data are collected, Kt. we only sample the marginal distribution, which is also Gaussian, of our S EIR parameterization, pd (K2):K. a distribution with a great deal of uncertainty, or dispersion, can have a small root mean square error compared to observations. each p K i is drawn from a Gaussian distribution conditioned on the most recent observations described above. we can form a forecast of ILI data for the entire season by propagating the p K i through our S EIR model. each p K i is drawn from a discretely sampled time series. the straw man forecast consists of a normal distribution at each corresponding time point in the forecast with an averaged mean and standard deviation. we can then evaluate the straw man\u2019s accuracy using the metric given in Eq (11). the end of the influenza season, used to calculate the duration, is when ILI goes below the 2% national baseline and remains there. there is a 1\u20132 week lag between a patient seeing a doctor and the case appearing in the ILI database. there is a need for the use of digital surveillance data available in near real-time to complement ILINet data. the correlation between each of the 50 articles access log time series and U.S. ILI data was computed. it was found that access log time series from the five articles mentioned above were much more highly correlated with the ILI data than the remaining articles. we only model the U.S. ILI data during the part of the year that we designate as the influenza season. we only model the U.S. ILI data during the part of the year that we designate as the influenza season. the exception to our maximum influenza season range is the 2009 H1N1 pandemic, which emerged in the late 2008\u20132009 season causing this season to be prolonged and an early start in 2009\u20132010 season. we highlight the weeks corresponding to our maximum influenza season over which we parameterize our forecast. in our model, the population is divided into epidemiological categories for each time t > 0 as follows: the proportion susceptible to flu S(t), the proportion exposed (and noninfectious, asymptomatic) E(t), the proportion infectious and symptomatic I(t) and the proportion recovered and immune R(t. we assumed recovered individuals are then immune to the disease for the remainder of the season. I d R d t = I S ( 0 ) = S 0 E ( 0 ) = E 0 I ( 0 ) = I 0 R ( 0 ) = 1 - ( S 0 + E 0 + I 0 ). the transmission coefficient, (t; 0,, c, w) is allowed to vary over the course of the flu season. the parameters c and w control the center (peak of elevated flu transmission) and width (duration of elevated flu transmission). a power-law scaling is used to model some aspects of heterogeneity in the influenza contact network. a solution of our model is determined by the parameterization vector p = ( S 0, E 0, I 0, 0,, c, w,,, ) T, (5). each choice of p yields a discretely sampled solution vector 1 : K = ( t T, 2 t T,, K t T, p T ) T. optimization problem p i = arg min p d 1 : K i - M p 2, (9) is achieved by applying a stochastic optimization algorithm [61, 62] and this process is repeated L times for each season. a log-normal distribution, fit to these samples, is chosen for 0(p) we use an ensemble Kalman smoother (enKS) [21, 67], with propagation always performed from the start of the influenza season, to assimilate the ILI/Wikipedia data into the transmission model. the enKS method we use is more sensitive to the underlying dynamics of the data timeseries. the enKS is similar to a standard ensemble Kalman filter except that instead of just using the most recent data to inform the forecast it uses a number of the most recent observations. this helps in estimating the underlying parameters by propagating the observation\u2019s information backward into the model ensemble\u2019s history. the last three sampled values of the infected proportion are used. we only sample the marginal distribution, which is also Gaussian, of our S EIR parameterization, pd (K2):K. the enKS method assumes that the forecast distributions are Gaussian. we can evaluate the forecast\u2019s precision by scaling the distance of our forecast mean from the observation using the ensemble covariance. the M-distance gives a description of the quality of the forecast. the straw man forecast consists of a normal distribution at each corresponding time point in the forecast with an averaged mean and standard deviation. we can then evaluate the straw man\u2019s accuracy using the metric given in Eq (11) we calculate weekly 5-number summaries for four quantities of interest. the start of the influenza season is defined to be the first week that ILI goes above 2% and remains elevated for at least 3 consecutive weeks. the end of the influenza season, used to calculate the duration, is when ILI goes below the 2% national baseline. the double peak in U.S. ILI data is due to under reporting during the holiday season in the u.s. however, the first peak can vary in its timing substantially and does not seem to be always present or strongly correlated with the holidays or emergence of separate influenza strains. our methods have determined that the average base time of transmission is 2\u20135 days, the average incubation time is 3\u20137 days, and the average recovery time is 6\u20138 days. this automatically lets us know that the recovery rate is tightly specified by our prior whereas the base transmission and incubation rates are not. the parameter c is represented in weeks since the beginning of simulation. a value c = 16 corresponds to the peak transmissibility during the 48th epidemiological week. a value w = 14 corresponds to 16 weeks of elevated transmission. this figure shows the prior forecast along with the 2013\u20132014 ILI data. the red line represents the median forecast from 300 samples of the prior. the dark blue and light blue regions represent the 50% and 90% credible regions centered around this median, respectively. forecast results illustrated in Fig 11 may seem disappointing at first glance. the variance in the forecast at epidemiological week 43 is quite large and the mean forecast underestimates the peak. even the 90% credible region of the forecast diverges from the tail of the epidemic. the 2013\u20132014 ILI data given the 2013\u20132014 ILI data up to epidemiological week 43 should have been assigned a lower probability based on previous seasons. based on previous ILI seasons it is not uncommon to see a much lower and later ILI peak given the ILI level at epidemiological week 43 for 2013\u20132014. the M-distance between forecast and ILI data is calculated for each epidemiological week until the end of the influenza season. the M-distances plotted for the straw man prediction use sample covariances and means calculated from 300 time series draws of the straw man forecast. the percentage improvement in the M-distance for the 2013\u20132014 ILI forecast using the data assimilative method compared to the straw man method is shown. the use of a mathematical influenza model with data assimilation provides up to a 20% improvement in the forecast with a minimum of a 10% improvement. this improvement is quickly degraded due to model bias close to the peak. a time series plot of the start week credible intervals for our seasonal S EIR forecast is shown in Fig 15. the high probability region for start week is usually 1\u20132 weeks after the actual 2013\u20132014 start week. however, the actual start week is contained within the 90% credible region until a week or two after the peak of flu season. 50% and 90% credible interval estimates of the influenza season peak week are plotted along with the median. forecasts for the size of the peak were widely varying in the 90% credible interval. but even with these draw backs the 50% credible region has a width of only 1%\u20132%. prior forecast Historical ILI data from the 2003\u20132004 U.S. influenza season through the 2012\u20132013 influenza season were used to generate our prior distribution of the seasonal S EIR model\u2019s parameterization. a new tab Ten seasonal heterogeneous S EIR model parameterizations for the U.S. ILI 2006\u20132007 data. this is a good example of the seasonal S EIR model\u2019s two areas of systematic divergence. Fig 6. Histogram of the marginal distribution for the average recovery time, measured in days. the rate parameter in our S EIR model,, is then the inverse of this average time. this distribution is concentrated over 6\u20137 days and skewed toward longer incubation times. the earlier the peak, the smaller its forecast height. it is also apparent that our forecast tapers off quickly after the peak occurs. in a typical influenza season, there are many more low ILI observations than high ILI observations. the dark blue region represents the region centered about the median in which 50% of forecasts fall, the light blue region represents where 90% of forecasts fall, and the red line represents the median forecast. the diamonds represent the 2013\u20132014 ILI data with the current data point marked by a red circle. the 2013\u20132014 season is mostly included in the 50% credible interval. this is most likely due to error in the original model and bias toward low influenza seasons in our prior. the accuracy of a probabilistic forecast should always be in terms of probability. after the peak of the influenza season, the straw man shows considerably smaller M-distance. this is due to the seasonal S EIR\u2019s inability to taper off slowly from the peak of the flu season. after the peak, our model has exhausted its susceptible proportion of the population, and the infected proportion rapidly goes to zero. the improvement of the data-assimilative forecast over the straw man forecast is more apparent if we look at the percent improvement in the M-distance that the data assimilative M-distance represents. the use of the S EIR model together with the enKS data assimilation scheme offers up to a 20% improvement in the M-distance of the straw man forecast. a time series plot of the start week credible intervals for our seasonal S EIR forecast is shown in Fig 15. a similar plot for the start week credible intervals for our seasonal S EIR forecast using the straw man model would show a constant distribution with median start week forecast at the 38th epidemiological week. the model adjusts by pushing the start week later into the season. this causes an overestimation of the start week that worsens as the season progresses. in practice, once the start week has been observed the forecast would be fixed. straw man's forecast does not assimilate current observations. a sample from the straw man forecast has no week-to-week correlations. the weekly forecasts can vary greatly from week to week. forecasts only need to predict the ILI data for 3 more weeks. distances in this 3-dimensional space grow much slower as a function of week-by-week error. the M-distance between forecast and ILI data is plotted. the peak of 2013\u20132014 ILI the use of the S EIR model together with the enKS data assimilation scheme offers up to a 20% improvement in the M-distance of the straw man forecast. the percent improvement in the M-distance for the U.S. 2013\u20132014 ILI forecast using the data assimilative method compared to the straw man method. the enKS applied to the S EIR model in the later ILI season tries to maintain an elevated ILI level by pushing the simulated peak forward in time. in practice, the forecast of quantities such as the start week would be fixed once they were observed. forecast for the ILI peak was uncertain with the 90% credible interval having width of around 6% until close to the actual peak. but the median forecast for the peak week was consistently within one or two weeks of the actual observed peak. this is a problem when computing the start week for the influenza season. a given straw man sample does not remain above 2% for consecutive weeks. for similar reasons the duration cannot even be defined for one time series sample of the straw man forecast. both methods were used on our data assimilation approach and on a much simpler forecast using estimated normal distributions. the inclusion of a straw man forecast as a baseline to evaluate our data assimilation scheme\u2019s usefulness is indispensable. the challenge now is to arrive at a model that more accurately represents influenza dynamics perhaps by including considerations made in [53, 55\u201359] our quantitative measure of forecast accuracy is motivated by the Gaussian likelihood function and has been used in many instances. a major concern for our epidemiological model is the systematic divergence from the data at the end of the influenza season. this divergence is evident in the optimal fitting done with our S EIR model on historical ILI data. the variability between regional ILI reporting methods poses a challenge beyond the. vaccination data are available but are not updated on a time scale fine enough to be comparable with weekly ILI. vaccination rates would directly reduce the proportion of the population susceptible to a given influenza strain. however, only sparse data are available on the actual proportion of the population susceptible to a given influenza strain. the method provides real-time model testing, model dependent prior estimation, evaluation of probabilistic disease forecasting, and transitioning from a deterministic model to a probabilistic forecast. if prior to the peak our model predicts an unexpected change in the future number of cases then this is an indication to public health decision makers that the model may be picking up on hidden events and trends. our method of data assimilation adjusted the allowable parameterizations and initializations of this model as ILI data became available. we also modeled the effect of heterogeneity in the influenza contact network and seasonal variation in the transmissibility of flu. a data assimilation method is used to sequentially tune a model of disease dynamics. but it highlights the need to use caution when adjusting the model to match data. if only the model parameterization and initialization are adjusted, this type of forecasting process allows one to identify the assumptions of the model that diverge from observations. a disease model that links spatial spread in each of these regions would have significantly more parameters to determine in a prior distribution. a disease model that links spatial spread in each of these regions would have significantly more parameters to determine in a prior distribution. there are regularly updated data on prevalence of specific strains provided by the WHO/NREVSS [6] and therefore, in retrospect, inclusion of multiple strains may be highly advantageous in the future."}