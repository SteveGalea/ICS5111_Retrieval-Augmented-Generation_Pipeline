{"summary": "re-sequencing and de novo sequencing of the majority of a bacterial genome is possible with read lengths of 20\u201330 nt. reads of 50 nt can provide reconstructed contigs of 1000 nt and greater that cover 80% of human chromosome 1. the leading methods for ultra high-throughput DNA sequencing fall into two main categories. the length of useful sequence that can be obtained is limited. the problem for these sequencing methodologies is that as the length of each individual read decreases, the probability that a read will occur more than once in the sequence increases. repAnalyse uses linear time suffix (18) and LCP (19) array construction algorithms. uniqueness analysis and simulated reassembly are performed by analysing this suffix array. each read is compared with every other read of the same length. the uniqueness for read length l is then given by Ul = nu,l/np,l. in both cases uniqueness has an approximately sigmoidal dependence on read length. this closely follows the behaviour of randomly generated sequences of the same size. the dashed curves show results for randomly generated sequences of the same size, which are content-biased to yield the same relative proportion of nucleotides given in ref. (27). a) Percentage of unique sub-sequences (U) for varying read length (l), the solid line shows uniqueness in the whole human genome, the dashed line shows uniqueness in human chromosome 1. it is also possible to reconstruct contigs from sections of DNA that have two or more identical repeats elsewhere in the genome. if there are two identical copies of a gene in the genome which differ only in the downstream non-coding sequence then it is possible to build a contig that contains the gene but this will be broken at the point where the downstream sequences differ. uniqueness has an approximately sigmoidal dependence on read length. this closely follows the behaviour of randomly generated sequences of the same size. the position of the rise in the bacterial genome is at higher read length. the dashed line shows uniqueness in human chromosome 1. the horizontal axis starts at 18 nt due to the limitations of reassembly below this length. in the extreme case of de novo sequencing, this map is not available. however it is not clear how reliable much of this information is. DISCUSSION Viral sequencing For the very short genome of -phage reads of 12 nt are 98% unique. re-sequencing by hybridization using probes of around 25 nt is now a reasonably well established technology and has been reported for the SARS Coronavirus (22). the uniqueness and reassembly analysis of the bacterial genome of E.coli K12 MG1655 show one main difference to that of both the viral genome and randomly generated sequences. 97% of the genome can be unambiguously probed by reads of 17 nt (Figure 1b) the remaining 3% is ambiguous for much longer read lengths. nt contigs significantly to 75%, with 96% of genes entirely covered by a single contig. this rises to 90 and 98%, respectively at a 50 nt read length. a significant portion can be reconstructed with much shorter read lengths. the human genome is much larger and more repetitive than that of E.coli. the challenges for short read sequencing approaches are expected to be much greater. read lengths of 25 nt would in principle probe 80% of the genome. s will be required for a significant percentage of sub-sequences to be unique making re-sequencing difficult. uniqueness also places an absolute limit on the read length required for de novo reassembly of the whole genome. the uniqueness analysis shows a rise reaching 50% uniqueness with 16 nt reads, 2 nt fewer than for the full genome. 87.5% of exons are covered by contigs of 200 nt or larger. reassembly was simulated from 25, 50 and 100 nt reads covering the whole of chromosome 17. our analysis shows that it is possible to completely reassemble the genome from 18 nt reads and that 17 nt reads can cover 99.6% of the genome with contigs larger than 10 000 nt. below this read length, coverage falls dramatically. this confirms and extends the result of Chaisson et al. (15) where it was found that a read length of 70 nt would allow a viral genome to be completely reassembled. a read length of 30 nt improves the coverage for 10 000 nt contigs significantly to 75%. a read length of 30 nt improves the coverage for 10 000 nt contigs significantly to 75%. a 70 nt read length would allow 93.4 and 99.5% of bacterial genomes. our analysis of the Caennorhabitis elegans genome showed that 88% of the sequence is covered by contigs larger than 1000 nt. by a read length of 100 nt a significant percentage (8.4%) of the genome is covered by contigs larger than 100 000 nt. this indicates that the whole genome shotgun sequencing of small eukaryotes is within the limitations of short read sequencing. single molecule (23) and sequencing by synthesis approaches claim read lengths of 25 to 115 nt are required to cover 90% of the genome. the largest re-sequencing project for the human genome focused on the non-repetitive sequences within chromosome 21. this allows the problem to be reduced to a series of smaller tasks. analysis shows that with reads of 50 nt it is possible to reassemble 80% of the chromosome into contigs larger than 1000 nt. 17% is covered by contigs larger than 10 000 nt. 98.4% of the chromosome maybe reassembled into contigs larger than 10 000 nt. reassembled contigs longer than 200 nt in the 81 090 nt of the BRCA1 gene. reassembly was simulated from 25, 50 and 100 nt reads covering the whole of chromosome 17. erroronious reads may result in incorrect sequence data, breaks within contigs and mis-assembly. the challenge for the future is to identify in detail the effect of different potential experimental errors."}