{"summary": "AMS algorithm for identification of post-translational modification sites in proteins based only on sequence information. the query protein sequence is dissected into overlapping short sequence segments. ten different physicochemical features describe each amino acid. therefore nine residues long segment is represented as a point in 90 dimensional space. the automatic prediction of PTM sites is now very important area of interest for the bioinformatics research community. the currently available PTM prediction tools can be categorized into four major groups based on the used types of classification schemes. PROSITE [5] predicts many types of PTMs based on the consensus of sequence patterns. the most popular server is NetPhosK that allows the user to choose its preferred 'threshold' value during prediction. the third category of methods involves several support vector machine (SVM) based prediction techniques. the prediction of Lysine acytelation sites is done using SVM [21] based classifiers. the PPSP predicted the plausible phosphorylation sites accurately for approximately 70 PK (Protein Kinase) groups. for our tests we choose the PPSP_balanced model that seems to provide the best overall performance for all types of protein families. AMS prediction tool is based on a feed-forward layered network of artificial neurons. each artificial neuron in the MLP computes a sigmoid function of the weighted sum of all its inputs. we have implemented three different network models for each type of PTM. the AMS 3.0 tool integrates heterogeneous classification schemes for different PTM types. it is designed in much more efficient and unique way to predict post-translational modifications than previously used ANN algorithms. the neural network is designed in much more efficient and unique way to predict post-translational modifications. the area under the ROC curve (AUC) is also calculated in the current experiment and presented in Table 1. The AUC is equivalent to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. biochim. biophys. Acta 576, 204-228 (1979) Selected KRIW790103 Side chain volume Biochim. Biophys. Acta 576, 204-228 (1979) Selected LAWE840101 Transfer free energy, CHP/water J. Biol. Chem. 259, 2910-2912 (1984) Selected OOBM850105 Optimized side chain interaction parameter Bull. AMS 2.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 AMS 3.0 (New SwissProt dataset) 84,38 90 97,92 97,92 0,977679 99,3 99,3 0,984574 Hydroxyproline - 28,8 85,71 89,62 94,06 0,942113 94,62 99,19 0,972567 Leucine amide - 98,97 97,96 98,1 99,36 0,989049 - - - Methionine amide - 100 93,75 100 93,75 0,66 85 86,17 97,59 0,928851 94,78 99,18 0,973369 Phospho autocatalysis 13,16 96,15 79,35 93,59 0,888392 95,96 99,15 0,97851 Phospho CDC2 85,71 80,9 89,55 75,95 0,916095 93,73 92,36 0,963488 Phosphoserine - 97,06 91,34 94,33 95 955236 - - Sulfotyrosine - 70,19 85,88 98,39 97,6 0,988929 99,48 98,47 0,990853 Valine amide - 94,29 97,06 98,57 98,57 0,986607 - - - - - - 98,56 96,07 0,949397 Phospho.ELM AMPK_group 6,25 100 - 73,33 64,36 0,839759 Phospho.ELM EGFR 0 0 - - 73,17 78,95 0,852909 Phospho.ELM GRK_group 2,7 100 - - 83,33 90,91 0,911404 Phospho.ELM GSK-3beta 18,37 75 - - - 85,29 64,44 0,896282 Phospho.ELM IGF1R 26,09 100 many researchers concentrated their efforts on prediction of four major kinase families, namely CDK, CK2, PKA and PKC. in the current work we have compared the performance of AMS3 with the existing state-of-the-art prediction systems for phosphorylation sites in protein sequences. in the current work we have compared the performance of AMS3 with the existing state-of-the-art prediction systems. KinasePhos_100 0,571 0,923 0,782 0,542 KinasePhos_bitscore 0,912 0,685 0,776 0,588 NetPhosK_0.3 1 0 0,4 N/A NetPhosK_0.5 0,639 0,748 0,705 0,387 NetPhosK_0.7 0,065 0,998 0,624 0,188 PPSP_highsens 0,983 0,075 0,438 0,128 PP _highspec 0,048 1 0,619 0,171 PredPhospho 0,594 0,959 0,813 0,616 Scansite_low 0,576 0,983 0,82 0,64 Scansite_high 0,38 0,997 0,75 0,512 Scansite_high 0,135 1 0,654 0,293 Meta Predictor 0,878 0,904 0,893 0,779 AMS 3 (trainset) 0,733 0,95 0,921 248 AMS 3 (train ROC values for four kinase families using GPS, KinasePhos, NetPhosK, PPSP, PredPhospho, Scansite and Meta Predictor. comparison of best recognition performances of different state-of-the-art phosphorylation site prediction programs with AMS-3. netPhosK 1.0 server predicts serine, threonine and tyrosine phosphorylation sites in eukaryotic proteins and netPhosK 1.0 server [11] predicts kinase specific eukaryotic protein phosphorylation sites. the performance of the server is reported on 5 different PTM types. the current design of the neural network implements three different network models for each of the PTM types by independently optimizing the network weights for optimum recall/precision/AUC values on randomly chosen test patterns. the efficiency of classification and the prediction power of our method, estimated on training and test datasets for each PTM types, clearly outperforms the previously reported results. the current version of the AMS is very fast in comparison to our previously developed SVM based version of the server. the current technique is very fast in comparison to our previously developed SVM based version of the server. we have implemented three different network models for each of the PTM types. the features for the current experiment are chosen by exhaustive experimentation on the AAindex database. the predictor tool reads primary protein sequences in FASTA format and decides whether an overlapping short amino acid sequence qualifies for a potential PTM site. the features for the current experiment are chosen by exhaustive optimization and search in all different hundreds (exactly 544 in the current version) of AAindex database release 9.0 http://www.genome.jp/aaindex/. ten different features are found that generate optimal recognition performance on the test datasets under consideration. a feed-forward artificial neural network is trained with back-propagation learning algorithm to optimize the classification accuracy between the positive and negative samples in the randomly chosen test dataset. the optimization procedure is tuned to produce separately optimum recall, precision and the AUC area for the test dataset chosen for each of the PTM types. the MLP classifier designed for the present work is trained with the Back Propagation algorithm. the algorithm is applied to minimize the sum of squared errors for the training samples by conducting a gradient descent search in the weight space. the number of neurons in a hidden layer is also varied during its training. each of these experiments is repeated at least 10 times by varying number of hidden neurons in the hidden layer of the network. the optimum networks, giving high AUC, recall and precision values with low error rates, are saved for further consideration. the problem of overfitting is addressed by optimizing each training network on independent test datasets. the predictor program reads these short sequences and generates output. the user can specify the type of PTM for specific prediction and the nature of optimization required. the output is generated in the following format. authors are also indebted to the contributions of the Centre for Microprocessor Applications for Training Education and Research (CMATER), computer science and engineering department, Jadavpur University, India. authors also acknowledge the contributions of many students, researchers and colleagues of CMATER in developing several key modules of the training and prediction routines."}