{"summary": "antibodies interact with proteins (called antigens) through their binding sites. the region of the antigen bound with the paratope is called epitope. a linear epitope is recognized by its linear sequence of amino acids. epitope-antibody recognition challenge consists of determining whether each peptide belongs to the positive or negative set starting from the data of the training set. a so-called \u201cbonus round\u201d was proposed beside this main challenge. a so-called \u201cbonus round\u201d was proposed beside this main challenge. DREAM 5 challenges dealt with the prediction of the reactivity of peptides to bind intravenous immunoglobulin (IVIg) antibodies. a set of 6841 peptides with high affinity was identified (positive set) from the same original set, 20437 peptides were identified showing no antibody binding activity in any of the triplicate assays. the predictive model of the peptide reactivity was trained on this dataset. the test set contained 13640 peptides and was formed by grouping the remaining 3421 positive peptides and the remaining 10219 negative peptides. only the sequence of these peptides was provided for the initial phase of the challenge. the amino acid frequencies (24 features) are calculated as the occurrence of each amino acid along the peptide. the four ambiguous amino acid B (asparagine or aspartic acid), X (unspecified or unknown amino acid), Z (glutamine or glutamic acid) and J (leucine or isoleucine) have also been considered. columns 2\u20136 report five of the most promising amino acid properties for predicting the peptide reactivity. antigenicity [9], accessibility [10], hydrophilicity [11], flexibility [12] and beta-turn propensity [13]. the beta-turn prediction was calculated by exploiting an amino acid scale of propensities following the Chou-Fasman method [2], [8], [13]. the size of the sliding window was chosen because it is known that the binding site covered by an antibody typically includes a stretch of 8 to 10 amino acids [36]\u2013[37]. the second set of features has been generated taking into account the entire training set. a peptide has a high value of MaxScore0_nw, if the negative examples contain at least another very similar peptide. the MaxScore feature is used to check the importance of the absolute value of a good alignment, while the DiffMaxScore attribute takes into account the difference between class groups. we decided to filter the features to obtain a more parsimonious model. linear regression gives the possibility to evaluate the contribution of each variable to classification. the outcome variable we considered is the reactivity value, which ranges from 1 to 65536. the distribution of these values shows that the outcome can be easily binarized. PART builds a partial decision tree and converts the best leaf into a rule. the minimum number of instances for each leaf was fixed at 1% of the examples. to evaluate the best classifier, the performances have been assessed using the so-called \u201cleave-one-out\u201d cross-validation approach. teams were ranked according to their performance score based on two metrics. the area under the precision versus recall curve was defined as the probability that a given or larger area under the curve value is obtained. the overall final score was defined as minus the logarithm of the geometric mean of the ROC and PR p-values. the final output of the bonus round should be a list of 1000 peptides for each of the three classes (i.e. H, L and M) the main idea is to generate de-novo peptides by extracting from the training set the motifs that characterize the epitope. negative clusters (L) - The clusters with at least eight sequences. the percentage of positive members is similar to the proportion of positive peptides. a multiple-alignment was then performed on the sequences of each cluster. the prediction has been used to rank the new peptides in terms of predicted reactivity. we selected the 1100 peptides with the highest predicted reactivity generated from the positive clusters and the 1100 with lowest predicted reactivity obtained from the negative clusters. training set contained 13638 peptides and was created by selecting 3420 peptides from the positive set and 10218 peptides from the negative set. two features of each peptide were provided: the amino acid sequence and a measure of the peptide reactivity to the IVIg antibodies. the goal is therefore to exploit the training set to develop a predictive model. participants are required to submit a ranked list of the peptides in the test set. they are ordered according to the predicted probability that the peptide belongs to the positive set (predicted reactivity) several approaches have been used for epitope prediction. the so-called scale-based approach exploited one or more scales of amino acid properties to weight each residues of the sequence of interest. the use of multiple scales was essential to predict epitope location reliably. antigenicity [9], accessibility [10], hydrophilicity [12], flexibility [12] and beta-turn propensity [13]. the antigenicity was calculated as proposed by Kolaskar et al. [9]. the frequency of the residue in antigenic determinants was exploited to calculate the antigenic propensity of each amino acid. for every peptide we computed: the maximum score obtained by the global alignment with every negative peptides (MaxScore0_nw); the maximum score obtained by the alignment against the positive set (MaxScore1_nw); the difference between MaxScore1_nw and MaxScore0_nw (DiffMaxScore_nw). the rationale for selecting the features mentioned above is related to the so-called classification for homology. a feature selection step was not mandatory because the training set was made of 13638 examples and the generated features were 37. we decided to filter the features to obtain a more parsimonious model. we applied three different procedures for feature selection. the model allows an easy interpretation of the results, since each variable can be separately considered. the main limits of this approach are the strong assumptions of conditional independence between variables and the need of choosing prior distributions. decision trees require the implementation of careful strategies to avoid overfitting. the DREAM 5 challenge was based on two metrics: the area under the precision versus recall curve and the area under the receiver operating characteristic curve. the overall final score was defined as minus the logarithm of the geometric mean of the ROC and PR p-values. the first set is computed from the peptide sequence. the values of all the features have been normalized between 0 and 1. in order to generate the first set of features, we exploited information about the peptides and the epitopes reactivity. we used the following peptide attributes: the sequence length, i.e. the number of residues of the peptide. columns 2\u20136 report five of the most promising amino acid properties for predicting the peptide reactivity. antigenicity [9], accessibility [10], hydrophilicity [11], flexibility [12] and beta-turn propensity [13]. the beta-turn prediction was calculated by exploiting an amino acid scale of propensities following the Chou-Fasman method [2], [8], [13]. the size of the sliding window was chosen because it is known that the binding site covered by an antibody typically includes a stretch of 8 to 10 amino acids [36]\u2013[37]. the second set of features has been generated taking into account the entire training set. the principle is that similar sequences have similar structures. a peptide has a high value of MaxScore0_nw, if the negative examples contain at least another very similar peptide. the DiffMaxScore attribute takes into account the difference between class groups. we mainly considered classifiers that provide a predictive model easy to be interpreted. linear regression gives the possibility to evaluate the contribution of each variable to classification. the outcome variable we considered is the reactivity value, which ranges from 1 to 65536. the PART method generates a decision list and converts the best leaf into a rule. the minimum number of instances for each leaf was fixed at 1% of the examples. to evaluate the best classifier, the performances have been assessed using the so-called \u201cleave-one-out\u201d cross-validation approach. teams were ranked according to their performance score based on two metrics. the area under the precision versus recall curve was defined as the probability that a given or larger area under the curve value is obtained by a random prediction. the overall final score was defined as minus the logarithm of the geometric mean of the ROC and PR p-values. the overall identity between any peptide sequence of the predicted peptides should not be higher than 5 within a stretch of 11 amino acid positions. the final output of the bonus round should be a list of 1000 peptides for each of the three classes. the main idea is to generate de-novo peptides by extracting from the training set the motifs that characterize the epitope. positive clusters (H) - The clusters with at least five sequences and where all the members are positive. Negative clusters (L) - The clusters with at least eight sequences and where all the members are negative. a multiple-alignment was then performed on the sequences of each cluster. the predictive model used in the main challenge (model B) was exploited to predict the reactivities of the remaining new peptides. the prediction has been used to rank the new peptides in terms of predicted reactivity. a motif was generated for every sequence 15 amino acids long. a residue was kept as constant in the motif if it satisfied the first constraint of the bonus round. the remaining amino acids are less conserved and do not satisfy the constraint of the bonus round. the predictive model used in the main challenge was exploited to predict the reactivities of the remaining new peptides. we selected the 1100 peptides with the highest predicted reactivity generated from the positive clusters and the 1100 with lowest predicted reactivity obtained from the negative clusters. 7 L 0.13 31.6% 9.17 0.22 M 0.35 35.2% 5.74 2.09 N 0.19 36.9% 3.11 2.08 P 0.26 34.3% 7.01 0.46 Q 0.43 38.9% 3.17 0.11 R 0.45 40.5% 7.78 1.56 S 0.51 33.1% 8.00 2.59 T 0.20 34.3% 4.72 0.25 V 0.11 33.9% 3.77 0.18 W 0.94 40.1% 8.78 0.43 Y 1.44 51.0% 11.51 4.49 B cross-validation of the classifiers was performed with a leave-one-out approach. the models obtained by applying decision tree and rules learner are reported in the supplementary material. the results of the classifiers are evaluated by leave-one-out cross-validation on three different subsets of features (A, B and C) the results are in general quite good, even if the difference between the results of the different classifiers is not statistically significant. logistic regression models obtained by considering feature subsets B and C have been evaluated in terms of their explanation capabilities. accessibility, flexibility and hydrophilicity were quite correlated. only flexibility was selected in subset B while only hydrophilicity was kept in subset C. both models have only an unexpected regression coefficient, in correspondence of flexibility (model B) and antigenicity (model C). both models have only an unexpected regression coefficient, in correspondence of flexibility and antigenicity (model C). model B showed a good positive correlation between the regression coefficients and the correspondent SRCs. in model C no correlation was found (i.e. Spearman correlation = 0.496 and p-value = 0.028), while in model C no correlation was found. the table shows the performance of all the participants to DREAM5 challenge 1. the results of our best final models are highlighted in bold. the final output of the bonus round is a list of 1000 new peptide sequences for each of the three classes: high reactivity (H), low reactivity (L) and medium reactivity (M). the procedure for the generation of these peptides follows the steps described in the Methods section and schematically reported in Figure 1. we selected the same number of peptides (i.e. 1100) both deriving from negative and positive clusters. the predicted reactivity of a peptide in the range [01] is given by the probability to belong to the positive class. I 0.04 33.5% 3.48 0.00 K 0.17 34.3% 6.52 2.07 L 0.13 31.6% 9.17 0.22 M 0.35 35.2% 5.74 2.09 N 0.19 36.9% 3.11 2.08 P 0.26 34.3% 7.01 0.46 Q 0.43 38.9% 3.17 0.11 R 0.45 40.5% 7.78 1.56 S 0.51 33.1% 8.00 2.59 T 0.20 34.3% 4.72 0.25 V 0.11 33.9% 3.77 0.18 W 0.94 cross-validation of the classifiers was performed with a leave-one-out approach. the models obtained by applying decision tree and rules learner are reported in the supplementary material. reactivity 84.95% 70.00% 89.96% 70.00% 70.00% Log. Reg. 85.54% 71.17% 90.35% 71.17% 71.17% 71.17% Naive Bayes 83.02% 66.14% 88.67% 66.14% 66.14% 88.67% 66.14% 66.14%. the best results are obtained after feature selection (subset B and C) this shows that some redundant information is present in the original set of features. in terms of F-measure, the logistic regression had a performance clearly higher than all the others. attributes associated to the presence of X, B and J are present in both subsets B and C. the features related to Alanine and Isoleucine have been removed only from subset C. both models have only an unexpected regression coefficient. the sign of the correlations follows the same pattern of the scale-based features. all the features are negatively correlated with peptide reactivity except for antigenicity. model B showed a good positive correlation between the regression coefficients and the correspondent SRCs. the table shows the performance of all the participants to DREAM5 challenge 1. the results of our two best final models are highlighted in bold. a new tab shows the ROC curve (top) and the Precision-Recall curve (P-R) calculated for the two best final models. logistic regressions fitted on the features contained in the subset B (model B) and in the subset C (model C) the subset B and C contain 28 and 27 remaining attributes, respectively. 78 1.56 S 0.51 33.1% 8.00 2.59 T 0.20 34.3% 4.72 0.25 V 0.11 33.9% 3.77 0.18 W 0.94 40.1% 8.78 0.43 Y 1.44 51.0% 11.51 4.49 B - 0.00 0.00 X 0.75 40.1% 0.00 0.00 J - 0.00 0.00 Z 0.66 40.9% 4.55 6.50 Antigenicity 0.49 31.6% 1.62 1.13 Accessibility 0.85 40.8% 0.00 0.00 decision tree and rules learner are reported in the supplementary material (see Text S1 and Text S2). Table 3 shows the results obtained in terms of mean accuracy, sensitivity, specificity, precision and F-measure. features Classifiers Acc Sens Spec Prec F-measure Subset A Lin.Reg. reactivity 85.01% 70.12% 90.00% 70.12% Lin.Reg. 85.21% 70.64% 90.09% 70.46% 70.55% Log. the results of the six classifiers are evaluated by leave-one-out cross-validation on three different subsets of features (A, B and C) the results of the classifiers are in general quite good. the results of the classifiers are in general quite good. logistic regression models obtained by considering feature subsets B and C have been evaluated in terms of explanation capabilities. we analyzed the two subsets of features by giving some explanations about the removed attributes. accessibility, flexibility and hydrophilicity were quite correlated. models are reported in Table 2, columns 4 and 5. they have only an unexpected regression coefficient, in correspondence of flexibility (model B) and antigenicity (model C) both models include only three scale-based features. model B showed a good positive correlation between the regression coefficients and the correspondent SRCs. in model C no correlation was found (i.e. Spearman correlation = 0.496 and p-value = 0.028) model B was the best final model, even if model C had a higher F-measure. the table shows the performance of all the participants to DREAM5 challenge 1. column 2\u20135 displays the Area under the Precision-Recall curve (AUPR), the Area under the ROC curve (AUROC), the p-value of AUPR (Pval AUPR) and p-value of (Pval AUROC), respectively. the final output of the bonus round is a list of 1000 new peptide sequences for each of the three classes: high reactivity (H), low reactivity (L) and medium reactivity (M). the procedure for the generation of these peptides follows the steps described in the Methods section. reactivity of the peptides of the two groups is predicted through the final best model proposed for the main challenge. we considered the binary classes 0-negative (reactivity between 1 and 1000) and 1-positive (reactivity between 10000 and 65536); the predicted reactivity of a peptide in the range [01] is given by the probability to belong to the positive class. logistic regression was one of the most widely used classifiers. the model had one of the best performances of the challenge. the model had one of the best performances of the challenge. some studies hypothesize that the flexibility is inversely proportional to antigenic propensity. a relatively high positive correlation was found between the flexibility and the minimum concentration needed to inhibit the E.Coli growth with antimicrobial peptides. this result confirms the appropriateness of the scale used for its calculation. the clusters have been used to extract a set of motifs that were the basis to generate an initial list of potential new peptides. the results of the experimental test of the real reactivity of these peptide sequences will be available in near future."}