{"summary": "the effective information can be used as a quantitative measure of phenotypic complexity of living organisms. the simpler the organism is, the less the information; the more complex the organism, the more the information. about 13% of human genome is estimated as effective information. the number of genes contained in the genome, rather than the genome size, correlated with the complexity of the organism. the human genome project and other model organism genome projects revealed that there are only about 25,000 genes in the human genome. simple organism nematode have 19,500 genes [3] and rice even has more genes than humans, 46,00055,000 [4] complexity is minimal for a homopolymer, and is maximal for a random sequence. complexity is equal to the sequence length, so is the most complex. complexity is the length of the sequence subtracting the Shannon's entropy. information is the difference between the entropy of known and unknown. the more uncertainty information decreases, the more information you need. information is the difference between the entropy of known and unknown. need information I = log 2 ( 10 8 ) = 26.57 bits The probability for each event is same here. you have to assume equal probability because in this way you need minimal information. we need to encode a protein sequence with 10 amino acids. information is the difference between the entropy of known and unknown. the more you know, the less the entropy of unknown, and the less the information you need. for a sequence, we can also say the information of the sequence is the information we need to write the sequence. the information content of the sequence can be calculated as [5,7,8]: C = H max H known = L H where L is the length of the sequence, H is the entropy of known. for example, for a sequence AXT, the first site A is very conserved with probability 1 for A, 0 for other base pairs. the information of the sequence is 2.5 bits. for each genetic codon, the amount of information is I=Hunknown- Hknown =3 log2(4)-0 = 6 bits. for each amino acid, the information content is different. organisms need to use a mechanism that can encode any protein sequences efficiently. for biological information, most cases are like this with maximum entropy needed to be reduced. the term \"effective information\" can be used to describe the minimal amount of information needed to construct an organism. a complex virus with hundreds of proteins may need to separate expression of early and late proteins and maintain precise ratios of different protein products expressed simultaneously. the quantities of protein expressions are controlled by the feedback through the affinity of regulatory factors to the binding sites. the information I2 for log(x) is of regulatory sequences. the x should be the number of protein linkage groups or operons. the real I2 in viruses is very possibly equal to x log(x) the information of sequence AACCCGG is 14 bits rather than 20 bits. the actual value of I1 should be exactly equal to the size of the protein coding area. for virus genomes with overlapping genes, we use the actual size of protein coding area instead of n 6. single strand DNA viruses have the minimum amount of effective information, down to 3 thousands bits. double strand DNA viruses have the maximum amount of effective information, up to hundreds of thousands of bits. effective information is roughly proportional to number of proteins or genome size. we can always think that a bacterium grows theoretically from producing the first protein molecule to the last molecule in sequence. in order to change protein expressions, organisms may use an information mechanism that can produce protein molecules one by one in sequence to reduce the maximum entropy to 0, which means each protein or operon has at least one regulatory sequence. effective information can be calculated: I = log ( N ) = y log ( x ) + n log ( 20 ) = I 2 + I 1 The formula to calculate I1 is the same as virus's. the formula to calculate I1 is the same as virus's. as 5 based on the genomic information structure of E. coli (about 3% of E. coli genome is estimated as regulatory information) this is equivalent to that that E. coli synthesizes 67 same protein molecules on average at a time. y is the total number of protein molecules in a bacterium. y is the total number of protein molecules in a bacterium. the effective information of some bacteria is as follows. the amounts of effective information of bacteria range from millions of bits to tens of millions of bits, just one order of magnitude higher than viruses. the amounts of effective information of bacteria range from millions of bits to tens of millions of bits, just one order of magnitude higher than viruses' the I value of haemophilus influenzae and Streptococcus pneumoniae exceeds the C value. the correct actual I value of haemophilus influenzae is 3.39e6 bits. the average length of proteins of Streptococcus pneumoniae is 250. the information to encode all the proteins is the size of the protein coding area in the genome, like bacteria's I1. overlapping genes account for considerable weight, and the overlapping genes account for considerable weight. a c n a c n a c n a c n a c n a c n a c n a c n k 2 = log ( C ) + k 2 ( t + a 1 + a 2 + + a c n ) log ( t ) = log ( C ) + k 2 x log ( t ) where k2 is a the number of unique sequences of clustered ESTs from human breast tumors is 6501[12], so we estimated t=6500 as the average cellular proteome size of differentiated cells. we can always think that cells are produced from the first one to the last one in sequence. the possibility is cn (z-1), i.e. there are cn types of cell to choose and the cell can be divided from any (z-1) cells. the number of possibilities to produce and deploy all cells can be calculated using permutation and combination formula. k3 is the average number of times one type of cells is generated. k3 is equivalent to that human body averagely generates 4.2e7 cells at once, that is about 0.012g. we adjusted the k3 value to make the I value of Schistosoma mansoni close to, but a little bit lower than the value of C. elegans. when z is very small, z is close to cn. that may make organisms once generate less than one cell. the formula can be calibrated as: I 3 = k 3 c n 1 + k 3 c n / z. the difference between the two databases is that TGI separated alternative splicing sequences and tried to produce tentative consensus, while UniGene put all the overlapping sequences together in one cluster. the number of human UniGene clusters should be equal to the number of genes. the total number of human genes is about 25,000, among which 3560% contain alternative splicing. ASPicDB only analyzed 18,193 genes, while human beings have 25,000 genes. the size of total transcriptome should be 326,552, which is quite close to the result of TGI. the species were chosen for two reasons: first, we chose the species with higher numbers of UniGene clusters among the close species because the data are still incomplete. secondly, the species should have TGI data or other data sources. some results of mammals obtained from TGI are lower than UniGene's. some results of mammals obtained from TGI are too old, or because there are real differences in the average number of alternative splicing among mammals. the data of the number of cell types of eukaryotes can be calculated. a linear relationship between the number of cell types cn and the size of complete transcriptome x can be drawn. the number of cell types cn increases linearly with x, until reaching saturation at mammal's 210. eukaryotes Species name x W(g) Gene or I1 I (bit) C (bit) I/C S. pombe (yeast) 5,206 9.5e-11 1.4e7bits[34] 1.59e7 2.76e7[35] 58% S. cerevisiae (yeast) 5,570[36] 9.5e-11 1.7e7bits[34] 1.91e7 2.42e7[37] 79% C. rein e-2 20,467[34] 1.05e8 4.2e9[41] 2.5% A. aegypti(mosquito) 25,773 0.02 15,419[42] 1.08e8 2.7e9[42] 4.0% S. purpuratus(sea urchin) 22,721 52.3 23,300[43] 1.27e8 1.6e9[43] 7.9% B. floridae(amphioxus) 25,304 the results demonstrate a definitive correlation between the amounts of effective information and the organismal phenotypic complexity defined by biological taxonomy and evolutionary theory. C. pombe has the lowest I value, while human beings have the highest. information is the difference between the entropy of known and unknown. the more uncertainty information decreases, the more information you need. information is the difference between the entropy of known and unknown. we need information I = log 2 ( 10 8 ) = 26.57 bits. if we know the sequence is an English sequence, then the entropy of unknown is H=10 log(4). if we know English, we will need much less information to write the sequence. information is the difference between the entropy of known and unknown. the more you know, the less the entropy of unknown, and the less the information you need. for a sequence, we can also say the information of the sequence is the information we need to write the sequence. the information content of the sequence can be calculated as [5,7,8]: C = H max H known = L H where L is the length of the sequence, H is the entropy of known. for a sequence AXT, the first site A is very conserved with probability 1 for A, 0 for other base pairs. the information of the sequence is 2.5 bits. for each genetic codon, the amount of information is I=Hunknown- Hknown =3 log2(4)-0 = 6 bits. Arg is more important, more protected from mutation, and more expression regulated than Trp. organisms need to use a mechanism that can encode any protein sequences efficiently. for biological information, most cases are like this with maximum entropy needed to be reduced. the term \"effective information\" can be used to describe the minimal amount of information needed to construct an organism. a complex virus with hundreds of proteins may need to separate expression of early and late proteins and maintain precise ratios of different protein products expressed simultaneously. if each protein is expressed one by one, the number of possibilities can be calculated. the information I2 for log(x) is of regulatory sequences. the x should be the number of protein linkage groups or operons. the real I2 in viruses is very possibly equal to x log(x) the information of sequence AACCCGG is 14 bits rather than 20 bits. the actual value of I1 should be exactly equal to the size of the protein coding area. for virus genomes with overlapping genes, we use the actual size of protein coding area instead of n 6 to calculate the effective information. single strand DNA viruses have the minimum amount of effective information, down to 3 thousands bits. double strand DNA viruses have the maximum amount of effective information, up to hundreds of thousands of bits. effective information is roughly proportional to number of proteins or genome size. a bacterium grows theoretically from producing the first protein molecule to the last molecule in sequence. in order to change protein expressions, organisms may use an information mechanism that can produce protein molecules one by one in sequence to reduce the maximum entropy to 0, which means each protein or operon has at least one regulatory sequence. effective information can be calculated: I = log ( N ) = y log ( x ) + n log ( 20 ) = k x log ( x ) = k x log ( x ) where k is the average number of times a protein is synthesized. can be estimated as 5 based on the genomic information structure of E. coli. this is equivalent to that E. coli synthesizes 67 same protein molecules on average at a time. the quantity of a protein molecules may be less than 5. y is the total number of protein molecules in a bacterium. y is the total number of protein molecules in a bacterium. the effective information of some bacteria is as follows. the amounts of effective information of bacteria range from millions of bits to tens of millions of bits, just one order of magnitude higher than viruses. the amounts of effective information of bacteria range from millions of bits to tens of millions of bits, just one order of magnitude higher than viruses. the I value of haemophilus influenzae and Streptococcus pneumoniae exceeds the C value. the actual protein average length of haemophilus influenzae is only 235 ( 308) and the actual size of protein coding area is only 3.26e6 bits. the calculated I1 value is 4.26e6 bits, which already exceeds the C value. information to encode all the proteins is the size of the protein coding area in the genome, like bacteria's I1. overlapping genes account for considerable weight, and the overlapping genes account for considerable weight. x t a 1 a 2 a 3 t a 3 k 2 C a c n a c n a c n t a c n k 2 = log ( C ) + k 2 ( t + a 1 + a 2 + + a c n ) log ( t ) = log ( C ) + k 2 x log ( t ) where k2 is a the number of unique sequences of clustered ESTs from human breast tumors is 6501[12], so we estimated t=6500 as the average cellular proteome size of differentiated cells. we can always think that cells are produced from the first one to the last one in sequence. the possibility is cn (z-1), i.e. there are cn types of cell to choose and the cell can be divided from any (z-1) cells. the number of possibilities to produce and deploy all cells can be calculated using permutation and combination formula. k3 is the average number of times one type of cells is generated. cn should be the number of cell types or the number of linkage groups. there is no regulatory information needed for genes or cells inside a linkage group. we adjusted the k3 value to make the I value of Schistosoma mansoni close to, but a little bit lower than the value of C. elegans. when z is very small, z is close to cn. that may make organisms once generate less than one cell. the formula can be calibrated as: I 3 = k 3 c n 1 + k 3 c n / z. the difference between the two databases is that TGI separated alternative splicing sequences and tried to produce tentative consensus, while UniGene put all the overlapping sequences together in one cluster. the number of human UniGene clusters should be equal to the number of genes. the total number of human genes is about 25,000, among which 3560% contain alternative splicing. the number of singleton sequences in the singleton should be about 10,00015,000. ASPicDB only analyzed 18,193 genes, while human beings have 25,000 genes. for plants is 22.5, to make the results from the two databases as consistent as possible. the species were chosen for two reasons: first, we chose the species with higher numbers of UniGene clusters among the close species. the species should have TGI data or other data sources. some results of mammals obtained from TGI are lower than UniGene's. if so, it will be difficult to understand the huge difference between mouse and rat. the data of the number of cell types of eukaryotes can be calculated. we know the number of cell types of adult human body is 210 [18]. sponges have 12 types of cell types [19]; the simplest multicellular organism Trichoplax adhaerens has 4 types of cell [20] eukaryotes Species name x W(g) Gene or I1 I (bit) C (bit) I/C S. pombe (yeast) 5,206 9.5e-11 1.4e7bits[34] 1.59e7 2.76e7[35] 58% S. cerevisiae (yeast) 5,570[36] 9.5e-11 1.7e7bits[34] 1.91e7 2.42e7[37] 79% C. rein 29 1.63e-2 20,467[34] 1.05e8 4.2e9[41] 2.5% A. aegypti(mosquito) 25,773 0.02 15,419[42] 1.08e8 2.7e9[42] 4.0% S. purpuratus(sea urchin) 22,721 52.3 23,300[43] 1.27e8 1.6e9[43] 7.9% B. floridae(amphioxus) the results demonstrate a definitive correlation between the amounts of effective information and the organismal phenotypic complexity defined by biological taxonomy and evolutionary theory. C. pombe has the lowest I value, while human beings have the highest. the effective information of Ciona intestinalis accounts for 69% of the genome. the x should be the number of transcripts that produce functional protein sequences. every TC in TGI should correspond to one protein sequence, and vice versa. all prokaryotes have the same k value and so do eukaryotes. the exact values of k can be determined when the genomic information structures of model organisms are completely clear. the information contained in I2 and I3 cannot be included in the sequences of regulatory proteins. phenotypic complexity of more organisms can be precisely calculated as effective information. results consistent to recent article regarding constrained sequence in eutherian mammals. data for volumes of bacteria can be found at website: http://www.ionizers.org/Sizes-of-Bacteria.html. the total cell number z of an organism is: z = w/v = (w/3) 1010, where w is the weight of the organism. there are statistical data for every organism. only the number of TC sequences is what we need. alternative splicing data can be found on the homepage. method to calculate the phenotypic complexity of organisms is a measure of uncertainty associated with the size of the genome sequence. the amount of effective genomic information needed to produce a gene/protein sequences from a random sequence is at least the information entropy of the system. the approach uses permutation and combination formulas to model the information needed to produce differentiated cells. eukaryotes: for genomes that are not sequenced, it is noted that I1 =6n g should be adjusted to the size of the protein-coding genes. in the calculation for eukaryotes: for genomes that are not sequenced, it is noted that I1 =6n g should be adjusted to the size of the protein-coding genes. a logical framework must be constructed so that information on genotypic complexity can be used to support the evolution of phenotypic complexity. this framework should be equally applicable to either the entire universe of organisms or only to a single organism such as eukaryotes. the authors may first focus on one organism and then apply the methodology to a broader subgroup of organisms. biologist may argue that there is always an increase in complexity if one follows the simple dictum that eggs come from preexisting eggs and multicellular organism evolves from single cell animals. questions can then be raised if viruses are therefore more primitive than rickettsiae, bacteria, fungi, algae, plants or animals. based evolution can operate on this set, there will be an increase in complexity. this increase in complexity is driven primarily by chemical potential and reduction in free energy. in a microbiological ecosystem with competing microorganisms, mutation-based evolution will increase the microorganism-based species diversity and drive up the number of ways free energy may be dispersed. the approach uses permutation and combination formulas to model the information needed to encode proteins for simple organisms. it also extends the method to compute the information needed to produce differentiated cells and to construct spatial structures formed by the cells in higher organisms. eukaryotes: for genomes that are not sequenced, it is noted that I1 =6n g should be adjusted to the size of the protein-coding genes. phenotypic complexity of life evolves in a single direction toward higher effective information measured by Shannon entropies. authors failed to demonstrate the relevance of genotypic complexity that is not defined in the paper. Shannon's information entropies can be used to support the evolution of phenotypic complexity. this framework should be equally applicable to either the entire universe of organisms or only to a single organism such as eukaryotes. the authors may first focus on one organism and then apply the methodology to a broader subgroup of organisms if not the whole universe of organisms. a single cell alga is more complex than rickettsiae, bacteria, fungi, algae, plants or animals. a single cell alga is more complex than rickettsiae, bacteria, fungi, algae, plants or animals. a single cell alga is more complex than bacteria. new molecular species capable of participating in the reaction set results in more ways to dissipate the free energy. mutation-based evolution will increase the microorganism-based species diversity and drive up the number of ways the free energy may be dispersed. also this results in an increase in entropy."}