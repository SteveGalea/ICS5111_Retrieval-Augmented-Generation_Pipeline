{"summary": "negative binomial distribution is used commonly throughout biology as a model for count data. most attention has focused on datasets that are not highly overdispersed (i.e. those with k1). accuracy of confidence intervals estimated for k is typically not explored. the NB distribution was shown to be a suitable model for the \u2018offspring distribution\u2019 for a number of disease transmission datasets [8]. the concept is the probability distribution for the number of individuals (termed \u2018secondary cases\u2019) infected directly by each infectious individual in a disease outbreak. all calculations in this study were conducted using, but all results and discussion are posed in terms of k. the term \u2018dispersion parameter\u2019 can refer to either k or ; other terms for k include \u2018shape parameter\u2019 and \u2018clustering coefficient\u2019. the disease transmission datasets analyzed by Lloyd-Smith et al. [8] fell into two broad categories, surveillance and outbreak datasets. each of these datasets presents challenges due to the processes by which data are generated and collected. resulting datasets are analogous to many other datasets in biology. n values, xi (i = 1, 2,..., n), generated as described below were simulated. the NB distribution can be derived as a Poisson distribution with gamma-distributed intensity, i.e. a Poisson-gamma mixture [23], [24] random variates were generated using the Matlab functions gamrnd and poissrnd. Raw data were drawn from a NB distribution with parameters m and k. each value xi was then decreased by an amount dibinomial(xi, pu), generated using the Matlab function binornd. x 1 is drawn from a NB distribution with parameters m and k. the xi are independent and identically distributed draws from the same NB offspring distribution. xi values corresponding to the first n infectious cases were used as the simulated outbreak dataset. the more extreme values of k are most difficult to estimate accurately. this work shows that it is better to make inferences about k indirectly via its reciprocal = 1/k, for two reasons. first, use of the reciprocal avoids discontinuities for homogeneous datasets, because increasing homogeneity yields 0 instead of k. direct ML estimates of k matched k = 1/ to beyond fourth decimal place. k = 1/ is much broader than the range of k commonly estimated from epidemiological data. NB distributions with k = 1000 and k (the Poisson distribution) are indistinguishable in practice. all simulations were conducted using Matlab v6.1 (MathWorks, Cambridge MA) n values, xi (i = 1, 2,..., n) were drawn from a gamma distribution with mean m and dispersion parameter k. each value xi was decreased by an amount dibinomial(xi, pu), generated using the Matlab function binornd. NB samples were generated as in section 2.1.1, then any value xi = 0 was deleted with probability pz. if the new value was also 0, then it was replaced with probability pz. each remaining value xi = 0 had avoided replacement exactly once. n values gi were drawn from a gamma distribution with mean m and dispersion parameter k. each of these values was used as the intensity parameter for a Poisson random variate to yield a NB-distributed value xi, i.e. xi = Poisson(gi) each outbreak was assumed to begin with a single infected individual. each of these cases infects x 1 other individuals, where the xi are independent and identically distributed draws from the same NB offspring distribution. the number of cases in the third generation is then simulated. the 90% CI was calculated, and it was recorded whether the true value k fell within the CI, above its upper bound (termed a CI underestimate) the more extreme values of k are most difficult to estimate accurately, and to match results presented in Lloyd-Smith et al. [8]. the ML estimate of was determined by unidimensional numerical maximization of the log-likelihood function [15], conducted using the fminbnd function of Matlab 6.1 over the interval (0.001,1000) the termination tolerance was set sufficiently small that negligible accuracy was lost in inverting the estimates. the CI for k was generated by inverting and reversing the endpoints of the interval for. when z 0.950, the upper bound of the interval for k was assumed to be k. results 3.1 Negative binomial data The results for unaltered NB datasets are shown in Figure 1. the true value of k fell below and above the estimated CI. for the 90% intervals estimated here, perfect coverage would yield values 5.0/5.0. for almost all parameter sets the proportion of CI overestimates is greater than 5%. 10,000 datasets were simulated as described in Section 2.1.3 of the text. Plotting details are described in Figure 1. 3.3 Negative binomial data with under-reporting of zeroes Results of estimation from NB surveillance datasets with under-reporting of zeroes. outbreak datasets yield slightly more CI overestimates for m = 3, even though the IQR and [5th, 95th] percentile interval of the sampling distribution is often smaller. 10,000 datasets were simulated as described in Section 2.1.4 of the text. 10,000 datasets were simulated as described in section 2.1.1 of the text. boxes show the median and interquartile range (IQR) of 10,000 resulting ML estimates of k. whiskers show the 5th and 95th percentile values. results for NB surveillance datasets subject to uniform under-counting are shown in Figure 2. when pu = 0.2, estimates of k differed only slightly from estimates from raw NB data. the probability with which any secondary case was missed by surveillance was (a) pu = 0.2. 10,000 datasets were simulated as described in section 2.1.4 of the text. no results are presented for n100 because fewer than 1 in 105 simulated outbreaks reached 100 cases. the distribution of m estimates has median value >1 and 5th percentile value 1. For m = 1, there is an upward bias in the m estimates that decreases as sample size rises. for m = 3, the upward bias persists but is very slight for k0.3 or n30. estimations were more biased and less precise for higher values of k. this effect arises because a NB distribution with k = 10 is qualitatively similar to one with k = 50 or k. the range of k estimates for small samples tends to be large and skewed upwards. overestimates of k favor CI overestimates by setting a high mid-point for the estimated intervals, and by reducing the estimated sampling variance. the gross patterns in the frequency of CI overestimates thus are driven primarily by patterns of bias in k. strained to positive values, CI overestimates are impossible when z 0.95. for given values of k>1, CI overestimates are more frequent for higher values of n and m (corresponding to lower values of ). this study's focus on overdispersed datasets has thus influenced the determination of CI coverage in some regions of parameter space. porting bias leads to systematic overestimation of k that does not vanish as n increases. NB distributions with low k are characterized by large zero classes and long tails. decreasing the proportion of zeroes leads to higher sample mean m and lower sample variance. the minimum value of m for an outbreak with n cases is (n1)/n (for an outbreak that dies out immediately following the n th case), while higher values are quite feasible. m is estimated as the mean number of secondary cases generated by the first n cases in an outbreak, regardless of whether the outbreak continues beyond n cases. overdispersion observed in disease transmission data [8] influences estimation of R 0 from continuous-time outbreak data such as daily case reports [28], [29], as opposed to estimation directly from known chains of transmission as assessed here. there is substantial risk of underestimating k, especially when sample sizes are small or the zero-class is under-counted. of k and associated CIs."}