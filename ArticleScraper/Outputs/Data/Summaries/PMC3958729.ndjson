{"summary": "most of the prediction models abounded in the literature can mainly be classified into two categories, namely, econometric models (casual model) and time series models. traditional research has been focusing on the economic factors of the take-off and landing point, such as population, income, and price. this hybrid approach arises from the fact that real-world time series are rarely pure linear or nonlinear but containing both linear and nonlinear patterns. neither ARIMA nor SVM can be adequate in modeling and forecasting time series because the ARIMA model cannot deal with nonlinear relationships while the SVM model alone is not able to handle both linear and nonlinear patterns equally well. the third contribution is to provide the experimental evidence on the performance of different multistep-ahead prediction strategies. the proposed hybrid methodology and multistep-ahead prediction strategies used in this study are discussed in section 4. p p 0, a t is white noise sequence, Ea t = 0, Ea 1 2 = 2. then x t is called autoregressive and moving average sequence. if the model is identified we can use the past value to predict the future. the coefficients and b are estimated by minimizing 1 2 T + C 1 n i = 1 n L ( y i, f ( x ). by introducing slack variables and *, Equation (3) can be transformed to the following constrained formulation. i = 1 n ( i i ) = 0, i, i [ 0, C ]. i = 1 n ( i i ) = 0, i, i [ 0, C ]. i = 1 n ( i i ) = 0, i, i [ 0, C ]. the final SVM regression function can be the following form: f ( x ) = i = 1 n ( i i ) K ( x i, x ) + b. (11) 2.1.3. ARIMA and SVM both have advantages in capturing linear or nonlinear patterns. iterated strategy and direct strategy are frequently selected for multistep-ahead forecasting. the first is named as the iterated strategy by Chevillon [19] and is often advocated in standard time series textbooks [20, 21]. the iterated prediction strategy learns one-step-ahead prediction model: t + 1 = f ( x t ) +, (17) where denotes the additive noise. after the learning process, the estimation of the H next values is returned by t + h = f ( t, t 1,..., t d + 1 ) if h = 1 f ( t + h 1, t + 1, t,..., t d direct strategy first embeds original series into H datasets D 1 = ( x t, y t 1 ) t = d N, D H = ( x t, y t 1 ) t = d N, (19) where x t t t,..., td+1, y th = t+h. then, the direct prediction strategy learns H direct models on D h = D 1,..., D H, respectively. y t (t = 1,2,..., n) includes the linear part L t and nonlinear part N t, namely, y t = L t + N t. for nonlinear time series t, the residuals of y t+h can be obtained by t + h = y t + h - L t + h. ence, deseasonalization, and detrending are performed on the data. then the multistep-ahead forecasting model is adopted. in nonlinear forecasting part, the parameter optimization algorithm PSO is employed to optimize the parameters of SVM. the model is called autoregressive and moving average sequence. once the model is identified, we can use the past value to predict the future. if the partial correlation function of a smooth sequence is trailing, sequence can be concluded for the AR model. introducing slack variables and *, Equation (3) can be transformed to the following constrained formulation: min 1 2 i, j = 1 n ( i i ) x i T x j i = 1 n i ( y i ) i ( y i ) (7) subject to i = 1 n ( i i ) = 0, i, i [ 0,. K(X i, x j) = (X i) (X j) = T(X j)(X i) = (x T x i + 1)p, RBF kernel function: K(x i, x j) = exp(||x ix j||2), sigmoid kernel function: K(x i, x j) = th(0 x T x + 1). ARIMA-SVMs Model Air passenger traffic demand is always affected by various factors such as economy, weather, and important events. the hybrid methodology that has both linear and nonlinear modeling capabilities can be a good strategy for practical use. the ultimate forecast value consists of linear forecast part and nonlinear forecast part. ARIMA Model ARIMA (p, d, q) is called Autoregressive Integrated Moving Average model. identifie smooth sequence using scatter chart, autocorrelation function, partial autocorrelation function, and ADF unit root test. if the partial correlation function of a smooth sequence is trailing, sequence can be concluded for the AR model. introducing slack variables and *, Equation (3) can be transformed to the following constrained formulation: min 1 2 i, j = 1 n ( i i ) x i T x j i = 1 n i ( y i ) i ( y i + ) (7) subject to i = 1 n ( i i ) = 0, i, i [ 0, C ]. K(X i, x j) = (x T x i + 1)p, RBF kernel function: K(x i, x j) = exp(||x ix j||2), sigmoid kernel function: K(x i, x j) = th( 0 x T x + 1). the hybrid methodology that has both linear and nonlinear modeling capabilities can be a good strategy for practical use. it is reasonable to consider a time series to be composed of a linear autocorrelation structure and a nonlinear component. iterated strategy and direct strategy multistep-ahead time series forecasting can be described as an estimation on future time series N+h, (h = 1,2,..., H) in the present study, iterated strategy and direct strategy are frequently selected for multistep-ahead forecasting. the iterated prediction strategy learns one-step-ahead prediction model: t + 1 = f ( x t ) +, (17) where denotes the additive noise. the estimation of the H next values is returned by t + h = f ( t, t 1,..., t d + 1 ) if h = 1 f ( t + h 1, t + 1, t,..., t d + h d direct prediction strategy learns H direct models on D h = D 1,..., D H, respectively. consider t + h = f h ( x t ) + h, h 1,..., H, (20) where denotes the additive noise. direct strategy first suggested by Cox [22] constructs a set of prediction models for each horizon using only its past observations. the direct strategy first embeds the original series into H datasets D 1 = ( x t, y t 1 ) t = d N, D H = ( x t, y t H ). the direct prediction strategy learns H direct models on D h = D 1,..., D H, respectively. consider t + h = f h ( x t ) + h, h 1,..., H, (20) where denotes the additive noise. for nonlinear time series t, the ultimate forecasted time series for y t+h is y t + h. for nonlinear time series t, the ultimate forecasted time series for y t+h is y t + h. for nonlinear time series t, the ultimate forecasted time series for y t+h is y t + h. four monthly air passenger traffic series of american airlines are chosen as experimental samples, namely, American Airlines, Delta Air Lines, Southwest Airlines, and United Airlines. the main reason of selecting these four airlines is that these airlines are famous in America and represent the development trend of air industry in America. air passengers traffic data are monthly and with strong seasonal components and trend patterns. deseasonalization and detrending are performed by means of the revised multiplicative seasonal decomposition presented in [24]. d y \u2032, (22) where x \u2032 = x E [ x z ], y \u2032 = y E [ y z ], (23) where X\u2032 and Y\u2032 are generalized to represent time series x(t) and lagged time x(t i) with time step i (i d) conditional on Z. input variable with highest conditional PMI value at every iteration can be added to inputs set. v id t and x id t denote the velocity and position of the ith particle in dth dimension at tth iteration. p i = p i1,..., p iD is called personal best (pbest) position. each particle takes individual (lbest) and social (gbest) information into account. no single accuracy measure can capture all the distributional features of the errors when summarized across data series. the first is the mean absolute percentage error (MAPE) defined as (25), the second is symmetric mean absolute percentage error (SMAPE) defined as (26), and the last accuracy measure is the mean absolute scaled error (MASE), defined as (27). the MAPE has the advantage of being scale-independent. x m(t) denotes the observation at period t for time series m, x m ( t) denotes the forecasted value of x m(t), M is the number of time series (in this case, M = 4), T is the number of observation in the hold-out sample (in this case, T = 48) and N is the number of observation in the estimation sample for time series m. a researcher should not perform Tukey HSD test unless the results of ANOVA are positive. a rank-based performance measure termed as multiple comparisons with the best [34] is used to test whether some models perform significantly worse than the best model. the input selection and model selection for each series are conducted using aforementioned filter method, PSO algorithm, and fivefold cross-validation with iterated and direct strategies. the measures MAPEh, SMAPEh, and MASEh are computed for each prediction horizon h over four time series. air passengers traffic data are monthly and with strong seasonal components and trend patterns. deseasonalization is performed by means of the revised multiplicative seasonal decomposition presented in [24]. the four sampling data series cover a period from January 1990 to December 2001, each with a total of 144 observations. the original data of these four airlines are shown in Figures 2(a) to 2(d). detrending is performed by fitting a polynomial time trend and then subtracting the estimated trend from the series. the best subset of inputs is selected a priori based only on the dataset. the partial mutual information [27] is used for the prediction models. the input variable with highest conditional PMI value at every iteration can be added to the inputs set. in this study, we chose the standard PSO algorithm to tune the parameters with the lowest MAPE on training sets. p i = p i1,..., p iD is called personal best (pbest) position. each particle takes individual (lbest) and social (gbest) information into account for updating its velocity and position. the process is terminated if the number of iterations reaches the predetermined maximum number of iterations. the MAPE has the advantage of being scale-independent and so is frequently used to compare forecast performance across different datasets. the MAPE also has the disadvantage that it puts a heavier penalty on positive errors than on negative errors. x m(t) denotes the forecasted value of x m(t), x m ( t) denotes the forecasted value of x m(t), x is the number of time series (in this case, M = 4), x is the number of observation in the hold-out sample (in this case, M = 48) and x is the number of observation in the estimation sample for time series m. 3.6. Implementations LibSVM (version 2.86) [35] is employed for SVR modeling here. we select the Radial basis function (RBF) as the kernel function. the PSO algorithm is employed in the current study. analysis of variance test procedures are used to determine if the means of performance measures are statistically different among the five models for each prediction horizon and dataset. results and Discussion The forecasting performance of the hybrid ARIMA-SVMs and benchmarking method on the four airlines' air passenger series covered a period from January 1990 to December 2001 are shown in Table 2. Results and Discussion. VM 6.341 7.213* 7.984 8.061* 8.632 8.259 8.894* 9.621* 8.126 1.556* SMAPE I-ARIMA 22.204 24.319 23.547 24.412 21.541 25.849 26.462 30.146 24.810 5.444 I-SVM 7.075 10.287 12.384 12.509 11.284 9.623 16.158 10.009 11.166 3.889 D-ARIMA 25.884 2.421 2.643* 5.027 2.740* 1.889* deseasonalization-detrending MAPE I-ARIMA 20.278 22.569 22.127 23.315 20.483 24.434 26.146 29.348 23.587 5.444 I-SVM 5.150 8.566 11.041 11.595 9.793 8.138 16.625 8.628 9.942 3.889 D-ARIMA 24.068 23.884 21.745 22.752 23. I-ARIMA means ARIMA model which employs direct strategy, the same as I-SVM, D-SVM, and D-ARIMA-SVM. for each accuracy measure and prediction horizon, the strategies are rank order from 1 (the best) to 6 (the worst) in Table 2. an ANOVA procedure is performed to determine if there exists a statistically significant difference between the six modeling strategies in the hold-out sample. the Tukey's HSD test is a post-hoc test, meaning that the results of the ANOVA procedure should not be performed unless the results are positive. I-ARIMA D-ARIMA I-ARIMA 8, 1\u201324 D-SVM D-ARIMA I-SVM I-SVM * I-ARIMA D-ARIMA 24 D-ARIMA-SVM * I-ARIMA D-ARIMA SMAPEh 1 I-ARIMA-SVM * I-SVM D-SVM * I-ARIMA D-ARIMA D-ARIMA SMAPEh 1 I-ARIMA-SVM * I-SVM D-SVM SVM D-ARIMA-SVM * D-SVM I-SVM * I-ARIMA D-ARIMA 4, 1\u201324 D-ARIMA-SVM D-SVM I-ARIMA-SVM * I-SVM * D-ARIMA I-ARIMA 8 D-SVM D-ARIMA-SVM * I-ARIMA 8 D-SVM D-ARIMA-SVM * I-ARIMA D-ARIMA 12 I-SVM D-ARIMA-SVM MA-SVM D-SVM I-SVM * D-ARIMA I-ARIMA 8, 1\u201324 D-SVM D-ARIMA-SVM * I-ARIMA I-SVM * D-ARIMA 12 D-SVM D-ARIMA-SVM * I-ARIMA I-SVM * D-ARIMA I-ARIMA SMAPEh 1 I-ARIMA-SVM * I-ARIMA D-ARIMA 2 D-ARIMA-SVM * I-ARI -ARIMA-SVM * I-SVM * D-ARIMA I-ARIMA 8 D-SVM D-ARIMA-SVM I-SVM * I-ARIMA 12 I-SVM D-ARIMA-SVM I-ARIMA 18 D-ARIMA-SVM D-SVM I-ARIMA-SVM * I-SVM D-ARIMA 24 I-SVM D-ARIMA-SVM I-ARIMA 1\u201324 D-ARIMA-SVM I quantitative and comprehensive assessments are performed with the air passengers traffic data on the basis of several prediction accuracies. a large scale comparative study has been conducted for validation."}