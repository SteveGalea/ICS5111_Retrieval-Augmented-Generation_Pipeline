{"summary": "sequence similarity-based approaches are widely used for function prediction. but they are often inadequate in the absence of similar sequences. results A highly accurate prediction method capable of identifying protein function is described. approaches for predicting and classifying protein functions play an important role in determining the functions of unknown proteins. if an unknown gene or protein sequence is identified, researchers may carry out a sequence similarity search using BLAST [1], PSI-BLAST [2], or FASTA [3] to find similar proteins or annotation information in public databases. as a result, sequence similarity-based approaches are often inadequate in the absence of similar sequences. icochemical properties, predicted secondary structures, subcellular location, sequence motifs or highly conserved regions have been used to obtain good predictive power. various machine-learning algorithms such as support vector machines (SVMs), neural networks, nave Bayes classifiers, and ensemble classifiers have been used to build classification and prediction models. et al. [45] demonstrated the ability of the SVM prediction method to identify potential drug targets. they obtained an accuracy of 84% in predicting known drug targets versus putative nondrug targets. protein function has been predicted using nave Bayes classification. ensemble classifiers have become popular for protein function classification. a wide variety of features or only a few meaningful features were selected to increase the performance of function prediction based on experience or a few heuristics. a method was developed to detect small changes in amino acids within a sequence. the method is characterised by three primary features designed to address specific problems inherent in protein function prediction. this approach was designed to accurately predict various protein functions over a broad range of cellular components. the dataset included 16,618 positive sample sequences and 35,619 negative sample sequences. negative samples for each protein class were selected from proteins that do not belong to that class. negative samples for each protein class were selected from proteins that do not belong to that class. 34 of the traditional features were extracted from the Swiss-Prot protein sequences. traditional features included amino acid composition, protein length, number of atoms, molecular weight, GRAVY, and theoretical isoelectric point (pI), among others. PPRDist(x, y) was defined as (4) where #PP(x, y) is the total number of PP occurrences in the interval from x to y. NNRDist(x, y) was computed as follows: (5) where #NN(x, y) is the total number of NN occurrences of the interval from x to y. all the traditional and novel features used in this study are described in detail in Table 2. Features used for protein function classification Feature Description Dimension 1 Number of amino acids Number of residues in each protein 1 2 Molecular weight Molecular weight of the protein 1 3 Theoretical pI The pH at which the net charge of the protein is zero (isoelectric point) 1 4 Amino acid composition Percentage of each amino acid in the protein 20 5 Positively charged residue_2 Percentage of positively charged residues in the protein s or from negatively charged residues to positively charged residues 1 21 NNRDist(x, y) Percentage of PNPR from x to y (local information) 10 23 PNPRDist(x, y) Percentage of PNPR from x to y (local information) 10 24 Charged Physicochemical property 1 25 Negatively charged residues Percentage of negatively charged residues in the protein 1 26 Polar Physicochemical property 1 27 Alipha filter and wrapper methods are used to select a specific subset of potentially discriminating features. correlation-based feature selection (CFS) [34,65] was used to select a subset of potentially discriminating features. filter methods are faster than wrapper methods because the former do not require the use of learning machines. a heuristic search is conducted to traverse the space of the feature set. the subset with the highest merit preserves the most important features. those that are highly correlated with the class and have low inter-correlation with one another. charged, polar, aliphatic, aromatic, hydrophobic and aromatic, hydrophilic and acidic, hydrophilic and basic, acidic, polar and uncharged Translation NumOfAAs, D, L, hydrogen, GRAVY, PPR, NNR, NNRD(11,20), PPRD(31,40), PPRD(41,50), PPRD(51,60), NNRD(91,100), AA, AG, AH, AM numOfAAs, theoretical pI, D, C, G, S, sulphur, instability index, aliphatic index, GRAVY, PPR, NNR, NNRD(11,20), PNPRD(21,30), NNRD(91,100), CN, DC, DM, EC, EW, FP, FW, FY, GA, HP, IN, LC, MW, NF, FW, FY, GA, HP MG, MH, MM, MR, NA, NP, PA, PC, PP, PR, PY, QM, QN, QP, RK, RR, RS, SM, SM, SY, TD, TR, RS, SM, SM, SM, SM, RS, SM, SM, SM, RS, SM, SM, SM, TD, RS, RS, SM, positively charged residue_2, NNRDist(81,90), DN, ER, FN, GD, GG, GN, GQ, GT, IN, IP, LC, LL, LT, NA, NG, PF, SQ, TA, TG, TN, TW, WK, WN, negatively charged residue, extinction coefficient_all, aliphatic index, GRAVY, NNR, PNPR, PPRDist(71, selection rates were then calculated as (33/451) 100 = 7.76% and (3/33) 100 = 9.09%. the selected features are highly correlated with the class and have low inter-correlation with each other. each dataset was randomly split into a training set (90%) and a blind test set (10%) no sample was included in both the training and testing sets. we present only the average performance of the 10-fold cross-validation process. the accuracy of predictions using the training dataset was determined using 10-fold cross validation. the accuracy of predictions using the training dataset was determined when building the classification model using the built model. random forests is a classification algorithm that employs an ensemble of classification trees that each use several bootstrap samples of training data and a randomly selected subset of features. libSVM [69,70] and random forests [68] were used as classification algorithms. an AUC and MCC of 1 indicate perfect prediction accuracy. the formula for the AUC of a classifier is as follows: (13) where S0 = ri, ri is the rank of the ith positive sample in the ranked list, n0 is the number of positive samples and 35,619 negative sample sequences. a total of 484 features were extracted solely from the protein sequences described in this study. traditional features included amino acid composition, protein length, number of atoms, molecular weight, GRAVY, and theoretical isoelectric point (pI), among others. spartic acid and glutamic acid have lower pIs, while positively charged residues repel each other. features representing the percentage change in charged residues and the distribution of charged residues were designed and computed. the alcohol dehydrogenase1A protein (Swiss-Prot:P07327) consists of 375 amino acids. the x value is the 76th amino acid (21%), the y value is the 113th amino acid (30%), and the value of PNP is 4. PNPRDist(21,30) is thus (4/375) 100 = 1.06667. atoms in the protein sequence 1 12 Sulphur Total number of sulphur atoms in the protein sequence 1 13 Extinction coefficient_All Amount of light a protein absorbs at a certain wavelength (assuming NO Cys residues appear as half cysteines) 1 15 Instability index The stability of the protein 1 16 Aliphatic index The relative volume of the protein occupied by aliphatic side chains 1 17 GRAVY Grand average of hydropathicity 1 18 PPR Per philic and basic Physicochemical properties 1 37 Acidic Physicochemical properties 1 38 Polar and uncharged Physicochemical properties 1 39 Amino acid pair ratio Percentage compositions for each of the 400 possible amino acid dipeptides 400 Total 484 Feature selection. primary goals of feature selection are to gain a more thorough understanding of the underlying processes influencing the data and to identify discriminative and useful features. a filter method uses a search algorithm to evaluate the merit of a feature subset. it eliminates irrelevant features, as they will be poor predictors of classes. the subset with the highest merit preserves the most important features. CY, FM, GW, HC, HR, IC, IG, LF, LG, LM, MF, MM, MQ, PC, QC, SC, TC, WD, YH, polar, hydrophobic, hydrophobic and aromatic, hydrophilic and basic Transcription D, C, Q, F, V, positively charged residue_3, sulphur, extinction coefficient_all, instability index, GRAVY, NNR, PNPR charged, aliphatic, hydrophilic and acidic Gluconate utilisation Positively charged residue_3, instability index, PNPRDist(11,20), PPRDist(21,30), PPRDist(31,40), PPRDist(91,100), AG, AH, AV, AW, AY, CC, CI, DG, DI, DR, EG, EW, FH, FL, FP, GC, GE, hydrophobic, hydrophobic and aromatic, hydrophilic and acidic, acidic, acidic Fatty acid metabolism NumOfAAs, R, D, C, Q, E, G, I, F, S, negatively charged residue, positively charged residue_3. NNRDist(11,20), NNRDist(71,80), AN, AT, CA, CC, CF, CN, CP, CS, DA, DF, DP, DS tiny G-protein coupled receptor Theoretical pI, D, C, Q, E, G, K, F, S, T, negatively charged residue, positively charged residue_3, sulphur, PNPR, PNPRDist(11,20), NNRDist(71,80), CC, CF, CH, CW, CY, FC, FI, FL, GQ, IC, IW, IY, LC, MW, SC, WG, W the number of traditional features selected was 33 of 451 features. the number of new features selected was 3 of 33 features. selection rates were then calculated as (33/451) 100 = 7.76%. gluconate utilisation 59 0.59 13.08% 15.15% Amino acid biosynthesis 52 0.309 11.53% 15.15% Fatty acid metabolism 90 0.303 19.96% 24.24% Acetylcholine receptor inhibitor 52 0.974 11.53% 9.09% G-protein coupled receptor 39 0.487 8.65% 9.09% Guanine nucleotide-releasing factor 69 0.36 15.30% 27.27% Fibre protein 31 0.481 6.87% 3.03% Transme 94.24 Transcription 3,644 3,872 415 421 87.78 85.04 96.62 96.65 94.25 94.61 94.65 94.73 Translation 139 1,886 16 210 98.81 98.67 98.37 97.78 97.87 96.90 98.07 97.34 Gluconate utilisation 53 420 7 46 98.73 98.94 98.11 validation, and accuracy of predictions using the test dataset was determined using the built model. the bold values mean the highest values among four methods. the abilities of the SVM and random forest techniques to predict and classify protein functions have recently been enhanced and found to be superior to other classification algorithms. the cost parameter used in the training process was selected from 0.5, 1, 2, 4, 6, 8, 10, 12. in the random forest method without feature selection analysis, the number of trees was 10 and the number of features was 6 or 7 because the number of features selected by the feature selection method was small. the random forest method without feature selection (RF_CFS) had the highest accuracy for classifying transcription, acetylcholine receptor inhibitor, guanine nucleotide-releasing factor, fibre, and transmembrane proteins (5 of the 11 protein classes). the random forest method without feature selection (RF_CFS) had the highest accuracy for classifying transport, gluconate utilisation, amino acid biosynthesis, fatty acid metabolism, and acetylcholine receptor inhibitor proteins (5 of the use of feature selection was found to improve classifier performance. for all other classifications, the use of feature selection improved classifier performance. for transport, transcription, amino acid biosynthesis, transmembrane proteins, both accuracy levels and AUCs significantly improved when feature selection was used. Detailed results for each method are presented in Tables 6, 7, 8, and 9 with a focus on sensitivity, specificity, F-measure, and MCC. the consistent performance of each method for predicting the protein functions of the 11 protein classes in both the 10-fold cross-validation test and the blind test demonstrates the validity of our methods. 79 99.73 0.72 0.71 Acetylcholine receptor inhibitor 100 100 1.00 1.00 G-protein coupled receptor 99.24 97.54 0.98 0.96 Guanine nucleotide-releasing factor 88.57 99.78 0.93 0.92 Fibre protein 83.33 100 0.91 0.91 Transmembrane 95.07 99.3 0.95 0.97 MCC: Matthew's correlation coefficient Table 8. Detailed results of the random forest method without feature selection (RF_FF anine nucleotide-releasing factor 85.71 99.55 0.90 0.89 Fibre protein 66.67 100.00 0.80 0.81 Transmembrane 94.62 98.83 0.96 0.94 MCC: Matthew's correlation coefficient. the additional experiments were carried out using the 451 traditional features versus the 33 proposed features. 98.7315 98.11 85.7 100 0.929 Amino acid biosynthesis 74.8627 77.83 42.6 100 0.713 73.5272 77.43 41.5 100 0.708 Fatty acid metabolism 92.4123 90.22 45.7 100 0.728 90.5586 87.77 32.1 100 0.66 Acetylcholine receptor inhibitor 98.448 99.06 80 100 0.9 100 99.53 100 99.5 0.998 G-protein the average number of new features selected by CFS was 5.4 for the 11 protein classes. the raw dataset was analysed for the selected features. guanine nucleotide-releasing factor was higher than negative samples. guanine nucleotide-releasing factor was 7.04 (mean) 1.72 (standard deviation) negative samples were 3.79 2.0. negatively charged residues appear more frequently in the guanine nucleotide-releasing factor sequence. the protein consists of 129 amino acids with five negatively charged residues. however, the positively and negatively charged residues in the sequence always alternate among the neutral residues. previous studies have analysed only the number or percentage of positively and negatively charged residues in the sequence. results indicate that continuous changes from a positively charged residue to the next negatively charged residue occurred more frequently over the full sequence of transcription proteins than in the negative samples. the mean values of the four selected features were significantly lower than those of the negative samples. selection of the optimal classifier for a given dataset depends on the type of data involved, the size of the dataset, the number of features involved, and whether feature selection is used. identifying discriminative features applicable to a broad range of protein classes is difficult. PPR and NNR were extracted from sequences based on the presence of negatively and positively charged residues. these new features include information on the existence of negatively and positively charged residues as well as the manner in which the two charged residue types co-exist in a sequence. these features appear to be highly correlated with protein class and have a low inter-correlation with each other. the random forest method with feature selection (RF_CFS) had the highest accuracy for classifying transcription, acetylcholine receptor inhibitor, guanine nucleotide-releasing factor, fibre, and transmembrane proteins (5 of the 11 protein classes). the RF_CFS method had the highest accuracy for classifying transport, gluconate utilisation, amino acid biosynthesis, fatty acid metabolism, and acetylcholine receptor inhibitor proteins (5 of the 11 protein classes). feature selection improved classifier performance. accuracy of transmembrane protein classification improved. accuracy of transmembrane protein classification improved. Detailed results of SVM without feature selection (SVM_FF) Protein class Sensitivity Specificity F-measure MCC Transport 31.54 100 0.48 0.46 Transcription 71.08 98.81 0.83 0.73 Translation 81.25 100 0.90 0.9 Gluconate utilisation 85.71 100 0.92 0.92 Amino acid biosynthesis 39.45 100 0.57 0.53 Fatty acid metabolism 30.86 100 0.47 0.52 Acetylcholine receptor inhibitor 100 99. -measure MCC Transport 87.58 95.89 0.84 0.91 Transcription 96.87 92.4 0.89 0.95 Translation 56.25 100 0.74 0.72 Gluconate utilisation 85.71 100 0.92 0.92 Amino acid biosynthesis 96.89 95.65 0.92 0.95 Fatty acid metabolism 71.6 100 0.82 0.84 Acetylcholine receptor inhibitor 100 100 1.00 1.00 G-protein coupled receptor 95.44 99.11 0.95 0.97 Guanine classification using only the 33 proposed features outperformed the 451 traditional features for 5 of the 11 protein classes. compared with the random forest method, classification using only the 33 proposed features was superior or equal to use of the 451 traditional features for 5 of the 11 protein classes. 76.1838 77.35 38.8 100 0.694 Guanine nucleotide-releasing factor 97.4359 97.92 77.1 99.6 0.883 98.8681 98.75 82.9 100 0.914 Fibre protein 96.789 95.89 0 100 0.5 99.8471 99.31 83.3 100 0.917 Transmembrane 85.2931 85.67 58.3 100 0.791 79.8937 80. .8745 97.18 94.7 98.7 0.993 Guanine nucleotide-releasing factor 96.7429 96.67 62.9 99.3 0.956 98.4985 97.92 74.3 99.8 0.992 Fibre protein 97.4771 95.89 33.3 98.6 0.798 99.2355 99.31 83.3 100 0.998 Transmembrane 93.555 93.52 87.4 9 negatively charged residues appear more frequently in the guanine nucleotide-releasing factor sequence. the NNR and PPR features are related to the number or percentage of negatively and positively charged residues. if the PPR for a specific protein family was high, then the number of negatively charged residues in that protein family was also low. negative residues at positions 440 and 441 were key residues that appeared to be involved in virus assembly. residues in specific positions or local regions of the sequences are also important. alternating positively and negatively charged residues occur more frequently in the local region than in the negative samples. negative samples showed fewer continuous changes from a positively charged residue to the next negatively charged residue or vice versa in the local region from 11% to 20% of the gluconate utilisation sequences. arginine, histidine, and lysine achieved better results than did arginine and lysine. selection of the optimal classifier depends on an understanding of machine-learning algorithms, feature selection processes, and biological background information relevant to the dataset. identifying discriminative features applicable to a broad range of protein classes is difficult. Currently, there is much more data available on protein sequences than on protein structures. feature selection improves predictions for a wide range of protein functions. but does not always ensure improved performance, depending on the dataset. features that show an obvious propensity for predicting proteins have not yet been reported. KHR and HSO supervised the work, provided useful suggestions to improve performance. all authors read and approved the manuscript."}